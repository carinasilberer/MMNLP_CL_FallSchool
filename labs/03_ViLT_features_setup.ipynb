{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b823a8a-8d32-4b59-9bd3-970ae45908da",
   "metadata": {},
   "source": [
    "# CL Fall School 2024 in Passau: Multimodal NLP\n",
    "Carina Silberer and Hsiu-Yu Yang, University of Stuttgart\n",
    "\n",
    "---\n",
    "\n",
    "# Lab 3: Word Similarity Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c4e5a0-243d-4361-b342-2c4aab9b2617",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf9acc5-6217-4dd8-8c46-46353130e349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - pytorch-nightly\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision -c pytorch-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66a4724-1001-47e0-bd2e-91ee1795fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee653e4-2950-4930-b0a1-482368e70c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import pandas\n",
    "except ModuleNotFoundError:\n",
    "    #!conda update -n base -c defaults conda\n",
    "    !conda install --yes pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1cb9d8-227a-403d-915f-fcbdf766d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "import operator\n",
    "import os\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00712cda-e17b-4dcc-849b-d4fa75db3c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7cea7-ad07-42c2-962b-cfe5f71d6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VIT \n",
    "# We need a processor to read in images in pixel values\n",
    "from transformers import ViTImageProcessor\n",
    "from transformers import ViTModel\n",
    "\n",
    "image_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch32-224-in21k')\n",
    "vit_model = ViTModel.from_pretrained('google/vit-base-patch32-224-in21k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d43ff6-3536-48b7-9e88-d4361eaa99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', clean_up_tokenization_spaces=True)\n",
    "text_model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a3710b-445d-47ef-9320-a41b03465d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltProcessor\n",
    "from transformers import ViltModel\n",
    "\n",
    "mm_processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-mlm\", clean_up_tokenization_spaces=True)\n",
    "mm_model = ViltModel.from_pretrained(\"dandelin/vilt-b32-mlm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550020c9-3d74-40d4-9936-43fe668e0ef5",
   "metadata": {},
   "source": [
    "# Exercise: Word Similarity Estimation\n",
    "Word similarity and relatedness datasets have long been used to intrinsically evaluate distributional representations of word meaning. The standard evaluation metric for such datasets is the [Spearman correlation coefficient (Spearman's $\\rho$)](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient). \n",
    "It is computed between the human-elicited scores and your model's estimated scores.\n",
    "\n",
    "The goal of this exercise is to compare 3 classes of models, a `pure language model`, a `pure vision model` and a `vision-language model` on the word similarity task. \n",
    "\n",
    "### Dataset: SimLex-999\n",
    "We will use the word pairs and human similarity judgements of SimLex-999.\n",
    "Download the dataset either from the course's github space (under `data/`), or from the website (https://fh295.github.io/simlex.html), the filename is `SimLex-999/SimLex-999.txt`. Check also the description of the dataset in the `README`. The relevant data for this assignment are provided in the columns `word1`, `word2`, `POS`, `SimLex999` (scale 0-10), and `concQ` (derived from  concreteness ratings (scale 1-7) for the individual words of a pair). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "294b80f6-c37a-42b1-a9c0-9655549159d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = pandas.read_csv(\"data/SimLex-999/SimLex-999.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b26b1104-8c9b-45b0-8782-a50a06c90b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fast</td>\n",
       "      <td>rapid</td>\n",
       "      <td>A</td>\n",
       "      <td>8.75</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>happy</td>\n",
       "      <td>glad</td>\n",
       "      <td>A</td>\n",
       "      <td>9.17</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.36</td>\n",
       "      <td>1</td>\n",
       "      <td>5.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>short</td>\n",
       "      <td>long</td>\n",
       "      <td>A</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stupid</td>\n",
       "      <td>dumb</td>\n",
       "      <td>A</td>\n",
       "      <td>9.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.36</td>\n",
       "      <td>1</td>\n",
       "      <td>5.26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weird</td>\n",
       "      <td>strange</td>\n",
       "      <td>A</td>\n",
       "      <td>8.93</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1</td>\n",
       "      <td>4.26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
       "0     old          new   A       1.58      2.72      2.81      2        7.25   \n",
       "1   smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
       "2    hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
       "3   happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
       "4    hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
       "5    fast        rapid   A       8.75      3.32      3.07      2        5.66   \n",
       "6   happy         glad   A       9.17      2.56      2.36      1        5.49   \n",
       "7   short         long   A       1.23      3.61      3.18      2        5.36   \n",
       "8  stupid         dumb   A       9.58      1.75      2.36      1        5.26   \n",
       "9   weird      strange   A       8.93      1.59      1.86      1        4.26   \n",
       "\n",
       "   SimAssoc333  SD(SimLex)  \n",
       "0            1        0.41  \n",
       "1            1        0.67  \n",
       "2            1        1.19  \n",
       "3            1        2.18  \n",
       "4            1        0.93  \n",
       "5            1        1.68  \n",
       "6            1        1.59  \n",
       "7            1        1.58  \n",
       "8            1        1.48  \n",
       "9            1        1.30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first 10 entries in SimLex-999\n",
    "sim_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7c616-7de8-4568-9540-8fbc65618f47",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "We load the models and prepare them and the vocabulary, and use Spearman's $\\rho$ to measure the correlation between the human-elicited similarity judgements and the model's estimated similarity scores. \n",
    "\n",
    "To cleanly disentangle the contribution of the respective modality, ensure the selected models have similar backbone/architecture. \n",
    "For example, ViLT's vision backbone is ViT. Ideally, we would also use ViLT's textual backbone, but since that was trained from scratch, we use the commonly used linguistic encoder BERT.\n",
    "\n",
    "* `Language model`: [BERT-base](https://huggingface.co/google-bert/bert-base-uncased) (**BERT**)\n",
    "* `Vision model`: [VIT](https://huggingface.co/docs/transformers/model_doc/vit#overview) (**ViT**)\n",
    "* `Vision-language model`: [ViLT](https://huggingface.co/docs/transformers/model_doc/vilt) (**ViLT**)\n",
    "\n",
    "\n",
    "##### Procedure:\n",
    "1. Step 1: (For vision-based models) Prepare visual input for words in the SimLex-999 dataset.\n",
    "2. Step 2: Load and prepare the models\n",
    "3. Step 3: Use the the models to extract the words and images' representation for calculating similarity scores\n",
    "4. Step 4: Calculating similarity scores\n",
    "5. Step 5: Use Spearman's $\\rho$ to measure the correlation between the human-elicited similarity judgements and the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
